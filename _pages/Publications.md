---
title: ""
permalink: /Publications/
author_profile: true
excerpt: ""
---

<div style="display: flex; align-items: flex-start; margin-bottom: 20px;">
  <img src="../images/dengjizhao.png" alt="test2" style="width: 150px; height: auto; margin-right: 20px; border-radius: 5px;">
  <div>
    <h3 style="margin: 0;">FR: Folded Rationalization with a Unified Encoder</h3>
    <p style="margin: 5px 0 10px;">Authors: <b>Wei Liu</b>, Haozhao Wang, Jun Wang, Ruixuan Li, Chao Yue, Yuankai Zhang </p>
    <p style="margin: 5px 0 10px;">Conference: NeurIPS 2022</p>
    <p style="margin: 5px 0 10px;">Task: Self-explaining rationalization in NLP. Problem: Degeneration. That's to say, in a cooperative game, the predictor and the generator (i.e., rationalizer) may collude to use uninformative rationale candidates to get the right label.</p>
    <p style="margin: 5px 0 10px;">Insights: If the whole model achieves high prediction accuracy, the generator can always learn the true semantic. Solution: Sharing the encoders between the generator and the predictor, which is very simple and is compatible with many variants of this kind of two-player rationaliser/classifier games. </p>
  </div>
</div>

[FR: Folded Rationalization with a Unified Encoder. (NeurIPS 2022)](https://arxiv.org/pdf/2209.08285.pdf)
===
- **Task:** Self-explaining rationalization in NLP
- **Problem:** Degeneration. That's to say, in a cooperative game, the predictor and the generator (i.e., rationalizer) may collude to use uninformative rationale candidates to get the right label.
- **Insights:** If the whole model achieves high prediction accuracy, the generator can always learn the true semantic.
- **Solution:** Sharing the encoders between the generator and the predictor, which is very simple and is compatible with many variants of this kind of two-player rationaliser/classifier games. 



[Decoupled Rationalization with Asymmetric Learning Rates: A Flexible Lipschitz Restraint.  (KDD 2023)](https://arxiv.org/abs/2305.13599)
===
- **Task:** Self-explaining rationalization in NLP
- **Problem:** Degeneration. That's to say, in a cooperative game, the predictor and the generator (i.e., rationalizer) may collude to use uninformative rationale candidates to get the right label.
- **Insights:** We first link the degeneration problem to the predictor's Lipschitz continuity. And then we link the predictor's Lipschitz continuity to the coordination of the predictor and the generator.
- **Solution:** Slow down the predictor, which is very simple and is compatible with many variants of this kind of two-player rationaliser/classifier games.

MGR: Multi-generator Based Rationalization
===
- **Task:** Causal discovery from a perspective of causal feature selection
- **Problem:** Previous causal discovery methods usually involve many assumptions for causal inference (e.g., the conditional independence assumed by a graphical model, and the ignorability of a SCM).
- **Insights:** We provide some insights into how to select causal features from a purely probabilistic perspective, which doesn't involve the above assumptions.

  

<div style="display: flex; align-items: flex-start; margin-bottom: 20px;">
  <img src="../images/dengjizhao.png" alt="test2" style="width: 150px; height: auto; margin-right: 20px; border-radius: 5px;">
  <div>
    <h3 style="margin: 0;">深度学习中的新突破</h3>
    <p style="margin: 5px 0 10px;">作者: 张三, 李四</p>
    <p style="margin: 5px 0 10px;">会议/期刊: NeurIPS 2023</p>
    <p style="margin: 5px 0 10px;">简介: 该论文提出了一种新型神经网络架构，显著提升了图像分类任务的准确率。</p>
    <a href="https://example.com" style="color: #0366d6; text-decoration: none;">阅读全文</a>
  </div>
</div>


